# CNN Training to detect sign language patterns 


## About the project
This project was developed as the final project for an ML professional certificate, where we could practice important things we had learned from the program. The project consists of training a convolutional neural network to categorize images into different options from sign language gestures. It was trained testing two different CNN model architectures and then a Hyperparameter tuning process was performed to get the best parameters for the model. During this Hyperparameter tunning process, a Bayesian optimization process was applied and run for 100 iterations to get the result after testing different combinations for the Hyperparameters. Finally, The model was trained with those parameters, reaching a 92% accuracy on the test set, meaning that the model accurately categorized 92% of the pictures from the test set.


## DATA
The data was obtained from a dataset available at Kaggle:
https://www.kaggle.com/datasets/datamunge/sign-language-mnist

![Screenshot](amer_sign2.png)

The dataset consists of 
A summary of the data you’re using, remembering to include where you got it and any relevant citations. 

## MODEL 
A summary of the model you’re using and why you chose it. 

## HYPERPARAMETER OPTIMSATION
Description of which hyperparameters you have and how you chose to optimise them. 

## RESULTS
A summary of your results and what you can learn from your model 

You can include images of plots using the code below:
![Screenshot](image.png)

## (OPTIONAL: CONTACT DETAILS)
If you are planning on making your github repo public you may wish to include some contact information such as a link to your twitter or an email address. 
